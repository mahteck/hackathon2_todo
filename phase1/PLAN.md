# Phase I Implementation Plan - In-Memory Python Console Todo App

**Project:** Evolution of Todo
**Phase:** I - Console Foundation
**Plan Version:** 1.0.0
**Status:** Ready for Task Breakdown
**Parent Documents:**
- [Global Constitution](../CONSTITUTION.md)
- [Phase I Constitution](./CONSTITUTION.md)
- [Phase I Specification](./SPECIFICATION.md)

---

## Plan Overview

### Objectives
1. Deliver a fully functional console-based Todo application
2. Establish foundational domain model for future phases
3. Demonstrate Spec-Driven Development workflow
4. Achieve â‰¥80% test coverage with passing tests
5. Create clear documentation for user onboarding

### Execution Strategy
- **Code Generation**: All production code generated by Claude Code based on specifications
- **Test-Driven Approach**: Write tests alongside implementation (not strictly before)
- **Incremental Validation**: Verify each step before proceeding to next
- **Documentation-Last**: Write user docs after implementation is stable

### Duration Estimate
- **Setup & Foundation**: Steps 1-2
- **Core Implementation**: Steps 3-5
- **Testing & Quality**: Step 6
- **Documentation & Polish**: Step 7

---

## Implementation Steps

---

### **Step 1: Project Structure Setup**

**Type:** ğŸ¤– **CODE GENERATION** (Claude Code Implementation)

#### Goal
Establish the Python project directory structure, configuration files, and development dependencies to support organized development and testing.

#### Inputs from Spec
- File structure from [SPECIFICATION.md Â§ File Structure](./SPECIFICATION.md#file-structure)
- Development dependencies from [SPECIFICATION.md Â§ Dependencies](./SPECIFICATION.md#dependencies)
- Python version requirement: 3.10+

#### Implementation Tasks
1. Create directory structure:
   ```
   phase1/
   â”œâ”€â”€ src/
   â”‚   â””â”€â”€ __init__.py
   â”œâ”€â”€ tests/
   â”‚   â””â”€â”€ __init__.py
   â”œâ”€â”€ requirements.txt
   â”œâ”€â”€ .gitignore
   â””â”€â”€ README.md (stub)
   ```

2. Generate `requirements.txt` with development dependencies:
   ```
   pytest>=7.4.0
   pytest-cov>=4.1.0
   mypy>=1.5.0
   ruff>=0.1.0
   ```

3. Create `.gitignore` with Python-specific ignores:
   ```
   __pycache__/
   *.py[cod]
   *$py.class
   .pytest_cache/
   .coverage
   htmlcov/
   .mypy_cache/
   .ruff_cache/
   ```

4. Create stub `README.md` with project title and placeholder sections

#### Expected Artifacts
- âœ… `phase1/src/` directory with `__init__.py`
- âœ… `phase1/tests/` directory with `__init__.py`
- âœ… `phase1/requirements.txt` with 4 dev dependencies
- âœ… `phase1/.gitignore` with Python ignores
- âœ… `phase1/README.md` stub

#### Acceptance Criteria
- [ ] Directory structure matches specification
- [ ] `requirements.txt` is valid and installable (`pip install -r requirements.txt`)
- [ ] `.gitignore` covers all common Python artifacts
- [ ] All `__init__.py` files exist and are valid (can be empty)

#### Validation Commands
```bash
cd phase1
python -m pip install -r requirements.txt
tree src tests  # Verify structure
```

---

### **Step 2: Domain Model & Data Layer**

**Type:** ğŸ¤– **CODE GENERATION** (Claude Code Implementation)

#### Goal
Implement the core data model (Task entity) and repository layer (in-memory storage) that will serve as the foundation for all business logic.

#### Inputs from Spec
- [SPECIFICATION.md Â§ Data Model](./SPECIFICATION.md#data-model)
  - Task TypedDict structure with 6 fields
  - Field validation rules and constraints
  - Storage structure (dict-based)
- [SPECIFICATION.md Â§ Implementation Notes Â§ task_repository.py](./SPECIFICATION.md#implementation-notes)
- [SPECIFICATION.md Â§ Exception Classes](./SPECIFICATION.md#error-handling)

#### Implementation Tasks

##### 2.1: Create `src/models.py`
- Define `Task` TypedDict with type hints:
  - `id: int`
  - `title: str`
  - `description: str`
  - `completed: bool`
  - `created_at: str` (ISO 8601)
  - `updated_at: str` (ISO 8601)
- Add docstring documenting all fields
- Add constants:
  - `MAX_TITLE_LENGTH = 200`
  - `MAX_DESCRIPTION_LENGTH = 1000`

##### 2.2: Create `src/exceptions.py`
- Define custom exception hierarchy:
  - `TodoAppError` (base)
  - `ValidationError` (inherits from TodoAppError)
  - `TaskNotFoundError` (inherits from TodoAppError)
  - `InvalidTaskIdError` (inherits from TodoAppError)
- Each exception with docstring and appropriate `__init__` method

##### 2.3: Create `src/task_repository.py`
- Implement `TaskRepository` class with:
  - `__init__()`: Initialize `_storage` dict and `_next_id` counter
  - `generate_id() -> int`: Return and increment next ID
  - `create(task_data: dict) -> Task`: Store task, return created Task
  - `find_by_id(task_id: int) -> Task | None`: Retrieve by ID
  - `find_all() -> list[Task]`: Return all tasks sorted by ID
  - `update(task_id: int, updates: dict) -> Task`: Update and return task
  - `delete(task_id: int) -> bool`: Remove task, return success
  - `clear()`: Reset storage (for testing)
- Full type hints on all methods
- Docstrings for all public methods

#### Expected Artifacts
- âœ… `src/models.py` (~40 lines)
  - `Task` TypedDict
  - Constants for max lengths
- âœ… `src/exceptions.py` (~50 lines)
  - 4 exception classes with docstrings
- âœ… `src/task_repository.py` (~120 lines)
  - `TaskRepository` class
  - 8 methods fully implemented

#### Acceptance Criteria
- [ ] All files pass type checking (`mypy src/`)
- [ ] All files pass linting (`ruff check src/`)
- [ ] Models can be imported without errors
- [ ] Repository can be instantiated and has all required methods
- [ ] Repository `generate_id()` produces sequential IDs (1, 2, 3...)
- [ ] Repository `create()` stores task in `_storage` dict
- [ ] Repository `find_all()` returns empty list when storage is empty

#### Validation Commands
```bash
cd phase1
mypy src/models.py src/exceptions.py src/task_repository.py
ruff check src/
python -c "from src.models import Task; from src.task_repository import TaskRepository; repo = TaskRepository(); print('OK')"
```

---

### **Step 3: Business Logic Layer**

**Type:** ğŸ¤– **CODE GENERATION** (Claude Code Implementation)

#### Goal
Implement the service layer that contains all business logic, validation rules, and orchestrates repository calls.

#### Inputs from Spec
- [SPECIFICATION.md Â§ Phase I Feature Specifications](./SPECIFICATION.md#phase-i-feature-specifications)
  - Feature 1: Add Task (with validation)
  - Feature 4: Update Task
  - Feature 5: Delete Task
  - Feature 6: Mark Complete
  - Feature 7: Mark Incomplete
- [SPECIFICATION.md Â§ Validation Rules](./SPECIFICATION.md#data-model)
- [SPECIFICATION.md Â§ Implementation Notes Â§ task_service.py](./SPECIFICATION.md#implementation-notes)

#### Implementation Tasks

##### 3.1: Create `src/task_service.py`
- Implement `TaskService` class with:
  - `__init__(repository: TaskRepository)`: Store repository reference
  - `add_task(title: str, description: str = "") -> Task`:
    - Validate title (non-empty, â‰¤200 chars)
    - Validate description (â‰¤1000 chars)
    - Strip whitespace from title
    - Generate timestamps (ISO 8601 format)
    - Create task via repository
    - Return created task
  - `get_all_tasks() -> list[Task]`:
    - Retrieve all tasks from repository
    - Return sorted by ID ascending
  - `get_task_by_id(task_id: int) -> Task`:
    - Validate task_id is positive integer
    - Retrieve from repository
    - Raise `TaskNotFoundError` if not found
    - Return task
  - `update_task(task_id: int, title: str | None = None, description: str | None = None) -> Task`:
    - Validate at least one field provided
    - Validate title if provided (non-empty, â‰¤200 chars)
    - Validate description if provided (â‰¤1000 chars)
    - Retrieve existing task
    - Update only provided fields
    - Update `updated_at` timestamp
    - Return updated task
  - `delete_task(task_id: int) -> Task`:
    - Validate task_id
    - Retrieve task (for return value)
    - Delete via repository
    - Return deleted task
  - `complete_task(task_id: int) -> Task`:
    - Retrieve task
    - Set `completed = True`
    - Update `updated_at` timestamp
    - Update via repository
    - Return updated task
  - `uncomplete_task(task_id: int) -> Task`:
    - Retrieve task
    - Set `completed = False`
    - Update `updated_at` timestamp
    - Update via repository
    - Return updated task

##### 3.2: Add helper functions
- `_validate_title(title: str) -> str`:
  - Strip whitespace
  - Check non-empty
  - Check â‰¤200 chars
  - Return stripped title or raise `ValidationError`
- `_validate_description(description: str) -> str`:
  - Check â‰¤1000 chars
  - Return description or raise `ValidationError`
- `_generate_timestamp() -> str`:
  - Return current time in ISO 8601 format
  - Use `datetime.now().isoformat()`

#### Expected Artifacts
- âœ… `src/task_service.py` (~250 lines)
  - `TaskService` class with 7 public methods
  - 3 private helper methods
  - Full type hints and docstrings

#### Acceptance Criteria
- [ ] File passes type checking (`mypy src/task_service.py`)
- [ ] File passes linting (`ruff check src/task_service.py`)
- [ ] Service can be instantiated with repository
- [ ] `add_task()` validates title and description
- [ ] `add_task()` raises `ValidationError` for empty title
- [ ] `add_task()` raises `ValidationError` for title >200 chars
- [ ] `update_task()` raises error if no fields provided
- [ ] All methods that accept task_id raise `TaskNotFoundError` for invalid IDs
- [ ] Complete/uncomplete methods are idempotent

#### Validation Commands
```bash
cd phase1
mypy src/task_service.py
ruff check src/task_service.py
python -c "from src.task_service import TaskService; from src.task_repository import TaskRepository; s = TaskService(TaskRepository()); print('OK')"
```

---

### **Step 4: CLI Interface Layer**

**Type:** ğŸ¤– **CODE GENERATION** (Claude Code Implementation)

#### Goal
Implement the command-line interface that handles user input, command parsing, output formatting, and error display.

#### Inputs from Spec
- [SPECIFICATION.md Â§ CLI Interface Specification](./SPECIFICATION.md#cli-interface-specification)
  - Command syntax for all 9 commands
  - Command parsing rules
  - Application lifecycle (startup, loop, shutdown)
  - Help command output
- [SPECIFICATION.md Â§ Phase I Feature Specifications](./SPECIFICATION.md#phase-i-feature-specifications)
  - CLI usage examples for each feature
  - Success response formats
  - Error message formats

#### Implementation Tasks

##### 4.1: Create `src/cli_formatter.py`
- Implement display helper functions:
  - `format_task_list(tasks: list[Task]) -> str`:
    - Generate formatted table with headers
    - ID | Status | Title | Created
    - Truncate titles >50 chars with "..."
    - Show summary (total, completed, incomplete)
    - Handle empty list case
  - `format_task_detail(task: Task) -> str`:
    - Display all task fields
    - Show "None" for empty description
  - `format_success(message: str) -> str`:
    - Return "âœ“ {message}" in green (if terminal supports colors)
  - `format_error(message: str) -> str`:
    - Return "âœ— Error: {message}" in red
  - `format_welcome() -> str`:
    - Return welcome banner
  - `format_goodbye() -> str`:
    - Return goodbye message
  - `format_help() -> str`:
    - Return complete help message with all commands

##### 4.2: Create `src/command_parser.py`
- Implement command parsing:
  - `parse_command(input_str: str) -> tuple[str, list[str], dict[str, str]]`:
    - Return (command_name, args, flags)
    - Handle quoted strings (titles with spaces)
    - Parse `--flag value` syntax for update command
    - Case-insensitive command names
  - `validate_command(command: str) -> bool`:
    - Check if command is valid
  - Constants:
    - `VALID_COMMANDS = ["add", "list", "view", "update", "delete", "complete", "uncomplete", "help", "exit"]`

##### 4.3: Create `src/main.py`
- Implement main application:
  - `main() -> None`:
    - Initialize repository and service
    - Display welcome message
    - Enter command loop (while True)
    - Parse and execute commands
    - Handle exceptions and display errors
    - Exit on "exit" command
  - `execute_command(command: str, args: list[str], flags: dict[str, str], service: TaskService) -> None`:
    - Route to appropriate handler based on command
    - Call service methods
    - Display formatted results
  - Command handlers:
    - `handle_add(args, service)`: Extract title and description, call `add_task()`
    - `handle_list(service)`: Call `get_all_tasks()`, format and display
    - `handle_view(args, service)`: Extract ID, call `get_task_by_id()`, display
    - `handle_update(args, flags, service)`: Extract ID and fields, call `update_task()`
    - `handle_delete(args, service)`: Extract ID, call `delete_task()`
    - `handle_complete(args, service)`: Extract ID, call `complete_task()`
    - `handle_uncomplete(args, service)`: Extract ID, call `uncomplete_task()`
    - `handle_help()`: Display help message
  - `if __name__ == "__main__": main()`

#### Expected Artifacts
- âœ… `src/cli_formatter.py` (~150 lines)
  - 7 formatting functions
- âœ… `src/command_parser.py` (~100 lines)
  - Command parsing logic
  - Input validation
- âœ… `src/main.py` (~200 lines)
  - Main loop
  - Command routing
  - 8 command handlers
  - Exception handling

#### Acceptance Criteria
- [ ] All files pass type checking
- [ ] All files pass linting
- [ ] Application starts and shows welcome message
- [ ] Help command displays all available commands
- [ ] Exit command terminates application gracefully
- [ ] Unknown commands show error message
- [ ] Application handles Ctrl+C gracefully (KeyboardInterrupt)

#### Validation Commands
```bash
cd phase1
mypy src/
ruff check src/
python src/main.py
# Manually test: help, exit commands
```

---

### **Step 5: Integration Testing**

**Type:** ğŸ¤– **CODE GENERATION** (Claude Code Implementation)

#### Goal
Verify that all features work end-to-end by implementing integration tests that simulate real user workflows.

#### Inputs from Spec
- [SPECIFICATION.md Â§ Testing Requirements Â§ test_integration.py](./SPECIFICATION.md#testing-requirements)
- [SPECIFICATION.md Â§ Acceptance Criteria Â§ Functional Requirements](./SPECIFICATION.md#acceptance-criteria)

#### Implementation Tasks

##### 5.1: Create `tests/conftest.py`
- Define pytest fixtures:
  - `empty_repository()`: Fresh TaskRepository instance
  - `repository_with_tasks()`: Repository with 3 sample tasks
  - `task_service(empty_repository)`: TaskService with empty repository
  - `task_service_with_data(repository_with_tasks)`: TaskService with sample data

##### 5.2: Create `tests/test_integration.py`
- Implement integration tests:
  - `test_complete_user_workflow()`:
    - Add task â†’ verify task exists
    - View all tasks â†’ verify in list
    - View task detail â†’ verify all fields
    - Update task â†’ verify changes
    - Complete task â†’ verify status
    - Delete task â†’ verify removed
  - `test_multiple_tasks_management()`:
    - Add 10 tasks
    - Complete 5 of them
    - Delete 2 of them
    - Verify correct counts and IDs
  - `test_error_recovery()`:
    - Trigger validation error (empty title)
    - Verify application continues
    - Successfully add valid task
  - `test_task_independence()`:
    - Create 3 tasks
    - Update task #2
    - Verify tasks #1 and #3 unchanged
  - `test_idempotent_operations()`:
    - Mark task complete twice â†’ no error
    - Mark task incomplete twice â†’ no error
  - `test_timestamp_behavior()`:
    - Create task â†’ record created_at
    - Wait 1 second
    - Update task â†’ verify updated_at changed, created_at same

#### Expected Artifacts
- âœ… `tests/conftest.py` (~50 lines)
  - 4 pytest fixtures
- âœ… `tests/test_integration.py` (~200 lines)
  - 6 integration test functions
  - Each test with docstring explaining scenario

#### Acceptance Criteria
- [ ] All integration tests pass: `pytest tests/test_integration.py -v`
- [ ] Tests cover all 7 core features
- [ ] Tests verify error handling
- [ ] Tests verify data integrity
- [ ] No test leaves side effects (fixtures ensure clean state)

#### Validation Commands
```bash
cd phase1
pytest tests/test_integration.py -v
pytest tests/test_integration.py --cov=src --cov-report=term-missing
```

---

### **Step 6: Unit Testing & Quality Assurance**

**Type:** ğŸ¤– **CODE GENERATION** (Claude Code Implementation)

#### Goal
Achieve â‰¥80% test coverage by implementing comprehensive unit tests for all layers (repository, service, models) and ensure code quality standards.

#### Inputs from Spec
- [SPECIFICATION.md Â§ Testing Requirements](./SPECIFICATION.md#testing-requirements)
  - test_task_repository.py: 9 test cases
  - test_task_service.py: 22 test cases
  - test_models.py: 3 test cases
- [SPECIFICATION.md Â§ Acceptance Criteria Â§ NFR4: Testing](./SPECIFICATION.md#acceptance-criteria)

#### Implementation Tasks

##### 6.1: Create `tests/test_task_repository.py`
- Implement repository layer tests:
  - `test_generate_unique_ids()`: IDs are 1, 2, 3... (sequential)
  - `test_create_task()`: Task stored with correct ID
  - `test_find_by_id_existing()`: Returns correct task
  - `test_find_by_id_not_found()`: Returns None
  - `test_find_all_empty()`: Returns empty list
  - `test_find_all_multiple()`: Returns all tasks sorted by ID
  - `test_update_task()`: Updates task in storage
  - `test_delete_task_existing()`: Removes task successfully
  - `test_delete_task_nonexistent()`: Returns False

##### 6.2: Create `tests/test_task_service.py`
- Implement service layer tests:
  - **Add Task Tests**:
    - `test_add_task_with_title_and_description()`
    - `test_add_task_with_title_only()`
    - `test_add_task_strips_whitespace()`
    - `test_add_task_empty_title_raises_error()`
    - `test_add_task_title_too_long_raises_error()`
    - `test_add_task_description_too_long_raises_error()`
  - **Get Tasks Tests**:
    - `test_get_all_tasks_empty()`
    - `test_get_all_tasks_multiple_sorted()`
    - `test_get_task_by_id_found()`
    - `test_get_task_by_id_not_found_raises_error()`
  - **Update Task Tests**:
    - `test_update_task_title_only()`
    - `test_update_task_description_only()`
    - `test_update_task_both_fields()`
    - `test_update_task_preserves_other_fields()`
    - `test_update_task_not_found_raises_error()`
    - `test_update_task_invalid_title_raises_error()`
    - `test_update_task_no_fields_raises_error()`
  - **Delete Task Tests**:
    - `test_delete_task_existing()`
    - `test_delete_task_not_found_raises_error()`
  - **Complete/Uncomplete Tests**:
    - `test_complete_task()`
    - `test_complete_task_already_complete_idempotent()`
    - `test_uncomplete_task()`
    - `test_uncomplete_task_already_incomplete_idempotent()`
  - **Timestamp Tests**:
    - `test_timestamps_set_on_create()`
    - `test_updated_at_changes_on_update()`
    - `test_created_at_immutable_on_update()`

##### 6.3: Create `tests/test_models.py`
- Implement model tests:
  - `test_task_has_all_required_fields()`: Verify Task TypedDict structure
  - `test_task_field_types()`: Verify type hints are correct
  - `test_constants()`: Verify MAX_TITLE_LENGTH and MAX_DESCRIPTION_LENGTH

##### 6.4: Run Quality Checks
- Execute full test suite with coverage
- Run type checking on all source files
- Run linting on all source files
- Fix any issues found

#### Expected Artifacts
- âœ… `tests/test_task_repository.py` (~150 lines, 9 tests)
- âœ… `tests/test_task_service.py` (~400 lines, 22 tests)
- âœ… `tests/test_models.py` (~50 lines, 3 tests)
- âœ… All tests passing
- âœ… Coverage report showing â‰¥80% coverage

#### Acceptance Criteria
- [ ] All unit tests pass: `pytest tests/ -v`
- [ ] Test coverage â‰¥80%: `pytest --cov=src --cov-report=term-missing`
- [ ] No type errors: `mypy src/`
- [ ] No linting errors: `ruff check src/ tests/`
- [ ] All test files have descriptive docstrings
- [ ] Each test function has clear docstring explaining what it tests

#### Validation Commands
```bash
cd phase1
pytest tests/ -v
pytest --cov=src --cov-report=html --cov-report=term-missing
mypy src/
ruff check src/ tests/
```

---

### **Step 7: Documentation & User Onboarding**

**Type:** ğŸ¤– **CODE GENERATION** (Claude Code Implementation)

#### Goal
Create comprehensive user-facing documentation that enables someone to set up, run, and use the Todo application without external help.

#### Inputs from Spec
- [SPECIFICATION.md Â§ CLI Interface Specification](./SPECIFICATION.md#cli-interface-specification)
- [SPECIFICATION.md Â§ Acceptance Criteria Â§ NFR5: Documentation](./SPECIFICATION.md#acceptance-criteria)
- All implemented features and their CLI examples

#### Implementation Tasks

##### 7.1: Update `README.md`
- Write comprehensive README with sections:
  - **Project Overview**: What is Phase I, what does it do
  - **Features**: List all 7 implemented features
  - **Requirements**: Python 3.10+
  - **Installation**:
    - Clone/download instructions
    - `pip install -r requirements.txt`
  - **Usage**:
    - How to start: `python src/main.py`
    - Basic workflow example
  - **Command Reference**:
    - Table of all commands with syntax and examples
    - Copy examples from SPECIFICATION.md
  - **Examples**:
    - Complete walkthrough: add â†’ list â†’ update â†’ complete â†’ delete
    - Screenshot of CLI session (as code block)
  - **Development**:
    - Running tests: `pytest`
    - Running with coverage: `pytest --cov=src`
    - Type checking: `mypy src/`
    - Linting: `ruff check src/`
  - **Architecture**:
    - Brief overview of 3-layer architecture
    - File structure explanation
  - **Limitations**:
    - In-memory only (no persistence)
    - Single-user
    - No persistence between sessions
  - **Migration to Phase II**: Note about future web app evolution

##### 7.2: Create `ARCHITECTURE.md`
- Document system design:
  - **Layer Diagram**: CLI â†’ Service â†’ Repository â†’ Storage
  - **Module Descriptions**:
    - `models.py`: Data structures
    - `exceptions.py`: Error types
    - `task_repository.py`: Data access
    - `task_service.py`: Business logic
    - `cli_formatter.py`: Display formatting
    - `command_parser.py`: Input parsing
    - `main.py`: Application entry point
  - **Data Flow**: Example of "add task" flowing through layers
  - **Design Decisions**:
    - Why TypedDict instead of dataclass
    - Why repository pattern in Phase I
    - How this prepares for Phase II migration

##### 7.3: Create `TESTING.md`
- Document testing approach:
  - **Test Structure**: Explain 4 test modules
  - **Running Tests**: Commands and options
  - **Coverage Goals**: 80% minimum
  - **Test Categories**:
    - Unit tests (repository, service, models)
    - Integration tests (end-to-end workflows)
  - **Adding New Tests**: Guidelines for contributors

#### Expected Artifacts
- âœ… `README.md` (~300 lines)
  - Complete user guide
  - All command examples
  - Installation and usage instructions
- âœ… `ARCHITECTURE.md` (~200 lines)
  - System design documentation
  - Module descriptions
  - Design rationale
- âœ… `TESTING.md` (~100 lines)
  - Testing guide
  - How to run tests
  - Coverage interpretation

#### Acceptance Criteria
- [ ] README has all required sections
- [ ] Installation instructions work on fresh environment
- [ ] Usage examples can be copy-pasted and work
- [ ] All 7 features documented with CLI examples
- [ ] Architecture diagram/description is clear
- [ ] Testing guide explains how to run and interpret tests
- [ ] Documentation is well-formatted (proper Markdown)

#### Validation Commands
```bash
cd phase1
# Verify README renders correctly
cat README.md

# Test installation instructions in fresh environment
python -m venv test_env
source test_env/bin/activate  # or test_env\Scripts\activate on Windows
pip install -r requirements.txt
python src/main.py
# Try commands from README
deactivate
rm -rf test_env
```

---

## Milestones & Dependencies

### Milestone 1: Foundation (Steps 1-2)
**Goal:** Project structure and domain model complete
**Deliverables:**
- [ ] Project structure created
- [ ] Models, exceptions, repository implemented
- [ ] Repository passes basic validation

**Dependencies:** None
**Estimated Effort:** ~20% of total effort

---

### Milestone 2: Core Implementation (Steps 3-4)
**Goal:** All features implemented and CLI functional
**Deliverables:**
- [ ] Service layer complete with all 7 operations
- [ ] CLI interface fully functional
- [ ] All commands work interactively

**Dependencies:** Milestone 1 complete
**Estimated Effort:** ~40% of total effort

---

### Milestone 3: Quality Assurance (Steps 5-6)
**Goal:** Comprehensive test coverage and quality gates passed
**Deliverables:**
- [ ] Integration tests passing
- [ ] Unit tests passing
- [ ] â‰¥80% code coverage
- [ ] Type checking passes
- [ ] Linting passes

**Dependencies:** Milestone 2 complete
**Estimated Effort:** ~30% of total effort

---

### Milestone 4: Documentation & Release (Step 7)
**Goal:** Production-ready with complete documentation
**Deliverables:**
- [ ] README.md complete
- [ ] ARCHITECTURE.md complete
- [ ] TESTING.md complete
- [ ] All acceptance criteria met

**Dependencies:** Milestone 3 complete
**Estimated Effort:** ~10% of total effort

---

## Acceptance Criteria Summary

### Functional Completeness
- [ ] All 7 features implemented (add, list, view, update, delete, complete, uncomplete)
- [ ] All CLI commands work as specified
- [ ] Help and exit commands work
- [ ] Error messages are clear and actionable

### Quality Gates
- [ ] âœ… Test coverage â‰¥80%
- [ ] âœ… All tests passing (unit + integration)
- [ ] âœ… No type errors (`mypy src/`)
- [ ] âœ… No linting errors (`ruff check src/ tests/`)
- [ ] âœ… All code has docstrings
- [ ] âœ… All functions have type hints

### User Experience
- [ ] Application starts with welcome message
- [ ] Commands are intuitive
- [ ] Error handling is graceful (no crashes)
- [ ] Help message is comprehensive
- [ ] Exit message confirms shutdown

### Documentation
- [ ] README with installation and usage instructions
- [ ] ARCHITECTURE documenting system design
- [ ] TESTING documenting test approach
- [ ] All commands documented with examples
- [ ] Limitations clearly stated

### Evolution Readiness
- [ ] Domain model documented for Phase II
- [ ] Business logic separated from presentation
- [ ] Data structures ready for JSON/DB serialization
- [ ] No hardcoded storage assumptions in service layer

---

## Risk Management

### Risk 1: Scope Creep
**Risk:** Adding features beyond the 7 specified
**Mitigation:** Strict adherence to SPECIFICATION.md; defer all enhancements
**Owner:** Human reviewer (spec approval)

### Risk 2: Test Coverage Below 80%
**Risk:** Insufficient test coverage prevents quality gate pass
**Mitigation:** Write tests alongside implementation; use coverage reports to identify gaps
**Owner:** Claude Code (implementation) + pytest-cov (measurement)

### Risk 3: Type Checking Failures
**Risk:** mypy errors block quality gate
**Mitigation:** Type hints added during initial implementation; run mypy incrementally
**Owner:** Claude Code (implementation) + mypy (validation)

### Risk 4: Overly Complex Architecture
**Risk:** Over-engineering for Phase I (building for Phase II prematurely)
**Mitigation:** Follow YAGNI principle; implement only what Phase I needs
**Owner:** Human reviewer (architecture review)

---

## Testing Strategy

### Test Pyramid
```
        /\
       /  \      3 Integration Tests (15%)
      /____\
     /      \    22 Service Tests (40%)
    /        \
   /__________\  12 Repository + Model Tests (45%)
```

### Coverage Targets by Module
- `models.py`: 100% (simple, critical)
- `exceptions.py`: 100% (simple, critical)
- `task_repository.py`: 90%+ (core data layer)
- `task_service.py`: 85%+ (business logic)
- `cli_formatter.py`: 70%+ (display logic, less critical)
- `command_parser.py`: 80%+ (input parsing)
- `main.py`: 60%+ (integration point, tested via integration tests)

**Overall Target:** â‰¥80% line coverage

### Test Execution
```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest --cov=src --cov-report=html --cov-report=term-missing

# Run specific test file
pytest tests/test_task_service.py -v

# Run specific test
pytest tests/test_task_service.py::test_add_task_with_title_and_description -v
```

---

## Dependencies

### External Dependencies
**Runtime:** None (Python 3.10+ standard library only)

**Development:**
- `pytest>=7.4.0` - Testing framework
- `pytest-cov>=4.1.0` - Coverage reporting
- `mypy>=1.5.0` - Type checking
- `ruff>=0.1.0` - Linting

### Internal Dependencies (Step Order)
1. **Step 1** â†’ No dependencies
2. **Step 2** â†’ Depends on Step 1 (project structure)
3. **Step 3** â†’ Depends on Step 2 (models, repository, exceptions)
4. **Step 4** â†’ Depends on Step 3 (service layer)
5. **Step 5** â†’ Depends on Steps 2-4 (all layers implemented)
6. **Step 6** â†’ Depends on Steps 2-4 (all layers implemented)
7. **Step 7** â†’ Depends on Steps 1-6 (complete implementation)

**Note:** Steps 5 and 6 can be partially parallelized (integration tests vs unit tests), but both must complete before Step 7.

---

## Code Generation Checklist

For each step marked ğŸ¤– **CODE GENERATION**, Claude Code must:

### Before Implementation
- [ ] Read relevant section(s) from SPECIFICATION.md
- [ ] Confirm understanding of acceptance criteria
- [ ] Identify all files to be created/modified

### During Implementation
- [ ] Generate code with full type hints
- [ ] Add docstrings to all classes and public functions
- [ ] Follow PEP 8 style guidelines
- [ ] Keep functions focused (â‰¤50 lines)
- [ ] Handle errors gracefully (no bare except blocks)

### After Implementation
- [ ] Run `mypy` on generated files
- [ ] Run `ruff check` on generated files
- [ ] Fix any type or linting errors
- [ ] Verify acceptance criteria for the step
- [ ] Document any deviations from spec (none expected)

---

## Execution Flow

```
START
  â†“
Step 1: Setup Structure (ğŸ¤– Generate)
  â†“
Step 2: Domain Model & Data Layer (ğŸ¤– Generate)
  â†“ [Validate: models, exceptions, repository work]
  â†“
Step 3: Business Logic Layer (ğŸ¤– Generate)
  â†“ [Validate: service layer works with repository]
  â†“
Step 4: CLI Interface (ğŸ¤– Generate)
  â†“ [Validate: app runs, commands work]
  â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â†“                           â†“
Step 5: Integration Tests    Step 6: Unit Tests
(ğŸ¤– Generate)                (ğŸ¤– Generate)
  â†“                           â†“
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“ [Validate: â‰¥80% coverage, all tests pass]
             â†“
Step 7: Documentation (ğŸ¤– Generate)
  â†“ [Validate: README complete, runnable]
  â†“
PHASE I COMPLETE âœ…
```

---

## Success Criteria (Phase I Complete)

### Must Have (Blocking)
- âœ… All 7 features work correctly via CLI
- âœ… Test coverage â‰¥80%
- âœ… All tests passing
- âœ… Type checking passes (mypy)
- âœ… Linting passes (ruff)
- âœ… README with complete usage instructions

### Should Have (Non-Blocking)
- âœ… Integration tests cover main user workflows
- âœ… ARCHITECTURE.md documents design
- âœ… TESTING.md explains test strategy
- âœ… Code has comprehensive docstrings
- âœ… Error messages are user-friendly

### Nice to Have (Future Enhancement)
- Command history (readline integration)
- Color output (terminal color support)
- Input auto-completion
- Task export to JSON (for Phase II migration)

---

## Phase I Retrospective (Post-Completion)

After completing all steps, document:
1. **What Went Well**: Successes and smooth processes
2. **What Could Improve**: Challenges and bottlenecks
3. **Lessons for Phase II**: Architectural insights, patterns to reuse
4. **Spec Refinements**: Any spec ambiguities encountered

This will feed into Phase II planning.

---

## Next Steps

**Current Status:** âœ… Plan Approved, Ready for Task Breakdown

**Next Command:**
```
/sp.tasks phase1
```

This will decompose each implementation step into atomic tasks that Claude Code can execute.

---

**Plan Version:** 1.0.0
**Created:** 2025-12-26
**Status:** APPROVED FOR TASK BREAKDOWN
**Approver:** Human + Claude Code
